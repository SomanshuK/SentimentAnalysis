{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-11T17:52:14.587526Z","iopub.execute_input":"2023-08-11T17:52:14.587943Z","iopub.status.idle":"2023-08-11T17:52:25.549773Z","shell.execute_reply.started":"2023-08-11T17:52:14.587908Z","shell.execute_reply":"2023-08-11T17:52:25.548571Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Set the device to GPU if available, otherwise CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:52:25.552191Z","iopub.execute_input":"2023-08-11T17:52:25.552673Z","iopub.status.idle":"2023-08-11T17:52:25.563203Z","shell.execute_reply.started":"2023-08-11T17:52:25.552619Z","shell.execute_reply":"2023-08-11T17:52:25.562159Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sentiment-analysis/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:52:25.564511Z","iopub.execute_input":"2023-08-11T17:52:25.566086Z","iopub.status.idle":"2023-08-11T17:52:25.746295Z","shell.execute_reply.started":"2023-08-11T17:52:25.566053Z","shell.execute_reply":"2023-08-11T17:52:25.745247Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:52:25.748915Z","iopub.execute_input":"2023-08-11T17:52:25.749207Z","iopub.status.idle":"2023-08-11T17:52:25.760277Z","shell.execute_reply.started":"2023-08-11T17:52:25.749182Z","shell.execute_reply":"2023-08-11T17:52:25.759325Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"      label                                              tweet\n0  Positive  im getting on borderlands and i will murder yo...\n1  Positive  I am coming to the borders and I will kill you...\n2  Positive  im getting on borderlands and i will kill you ...\n3  Positive  im coming on borderlands and i will murder you...\n4  Positive  im getting on borderlands 2 and i will murder ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Positive</td>\n      <td>I am coming to the borders and I will kill you...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Positive</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['label'] = df['label'].replace({'Positive': 1, 'Negative': 0, 'Neutral':3, 'Irrelevant':4})","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:52:25.761913Z","iopub.execute_input":"2023-08-11T17:52:25.763022Z","iopub.status.idle":"2023-08-11T17:52:25.825817Z","shell.execute_reply.started":"2023-08-11T17:52:25.762983Z","shell.execute_reply":"2023-08-11T17:52:25.824904Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:52:25.827344Z","iopub.execute_input":"2023-08-11T17:52:25.827708Z","iopub.status.idle":"2023-08-11T17:52:25.839966Z","shell.execute_reply.started":"2023-08-11T17:52:25.827661Z","shell.execute_reply":"2023-08-11T17:52:25.838883Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"       label                                              tweet\n0          1  im getting on borderlands and i will murder yo...\n1          1  I am coming to the borders and I will kill you...\n2          1  im getting on borderlands and i will kill you ...\n3          1  im coming on borderlands and i will murder you...\n4          1  im getting on borderlands 2 and i will murder ...\n...      ...                                                ...\n73991      1  Just realized that the Windows partition of my...\n73992      1  Just realized that my Mac window partition is ...\n73993      1  Just realized the windows partition of my Mac ...\n73994      1  Just realized between the windows partition of...\n73995      1  Just like the windows partition of my Mac is l...\n\n[73996 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>I am coming to the borders and I will kill you...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>im getting on borderlands and i will kill you ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>im coming on borderlands and i will murder you...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>73991</th>\n      <td>1</td>\n      <td>Just realized that the Windows partition of my...</td>\n    </tr>\n    <tr>\n      <th>73992</th>\n      <td>1</td>\n      <td>Just realized that my Mac window partition is ...</td>\n    </tr>\n    <tr>\n      <th>73993</th>\n      <td>1</td>\n      <td>Just realized the windows partition of my Mac ...</td>\n    </tr>\n    <tr>\n      <th>73994</th>\n      <td>1</td>\n      <td>Just realized between the windows partition of...</td>\n    </tr>\n    <tr>\n      <th>73995</th>\n      <td>1</td>\n      <td>Just like the windows partition of my Mac is l...</td>\n    </tr>\n  </tbody>\n</table>\n<p>73996 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_X, temp_X, train_y, temp_y = train_test_split(df['tweet'], df['label'],random_state=42, test_size=0.3, stratify=df['label'])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:52:25.841781Z","iopub.execute_input":"2023-08-11T17:52:25.842288Z","iopub.status.idle":"2023-08-11T17:52:25.887524Z","shell.execute_reply.started":"2023-08-11T17:52:25.842253Z","shell.execute_reply":"2023-08-11T17:52:25.886555Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"val_X, test_X, val_y, test_y = train_test_split(temp_X, temp_y,random_state=42, test_size=0.5, stratify=temp_y)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:52:25.888987Z","iopub.execute_input":"2023-08-11T17:52:25.890046Z","iopub.status.idle":"2023-08-11T17:52:25.907210Z","shell.execute_reply.started":"2023-08-11T17:52:25.890011Z","shell.execute_reply":"2023-08-11T17:52:25.906227Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:52:25.908941Z","iopub.execute_input":"2023-08-11T17:52:25.909311Z","iopub.status.idle":"2023-08-11T17:52:26.088876Z","shell.execute_reply.started":"2023-08-11T17:52:25.909277Z","shell.execute_reply":"2023-08-11T17:52:26.087866Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenizer(list(train_X), truncation=True, padding=True, max_length=100)\nval_encodings = tokenizer(list(val_X), truncation=True, padding=True,max_length=100)\ntest_encodings = tokenizer(list(test_X), truncation=True, padding=True,max_length=100)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:52:26.092418Z","iopub.execute_input":"2023-08-11T17:52:26.092704Z","iopub.status.idle":"2023-08-11T17:53:28.674420Z","shell.execute_reply.started":"2023-08-11T17:52:26.092679Z","shell.execute_reply":"2023-08-11T17:53:28.673360Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Convert labels to tensors\ntrain_y = torch.tensor(train_y.values)\nval_y = torch.tensor(val_y.values)\ntest_y = torch.tensor(test_y.values)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:53:28.676271Z","iopub.execute_input":"2023-08-11T17:53:28.676666Z","iopub.status.idle":"2023-08-11T17:53:28.682789Z","shell.execute_reply.started":"2023-08-11T17:53:28.676623Z","shell.execute_reply":"2023-08-11T17:53:28.681845Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_X = torch.utils.data.TensorDataset(torch.tensor(train_encodings['input_ids']),torch.tensor(train_encodings['attention_mask']),train_y)\nval_X = torch.utils.data.TensorDataset(torch.tensor(val_encodings['input_ids']),torch.tensor(val_encodings['attention_mask']),val_y)\ntest_X = torch.utils.data.TensorDataset(torch.tensor(test_encodings['input_ids']),torch.tensor(test_encodings['attention_mask']),test_y)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:53:28.684217Z","iopub.execute_input":"2023-08-11T17:53:28.684814Z","iopub.status.idle":"2023-08-11T17:53:33.451964Z","shell.execute_reply.started":"2023-08-11T17:53:28.684780Z","shell.execute_reply":"2023-08-11T17:53:33.450919Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ntrain_loader = DataLoader(train_X, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_X, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_X, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:53:33.453385Z","iopub.execute_input":"2023-08-11T17:53:33.453835Z","iopub.status.idle":"2023-08-11T17:53:33.463303Z","shell.execute_reply.started":"2023-08-11T17:53:33.453792Z","shell.execute_reply":"2023-08-11T17:53:33.462355Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train_loader","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:53:33.464817Z","iopub.execute_input":"2023-08-11T17:53:33.465179Z","iopub.status.idle":"2023-08-11T17:53:33.478456Z","shell.execute_reply.started":"2023-08-11T17:53:33.465145Z","shell.execute_reply":"2023-08-11T17:53:33.477066Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader.DataLoader at 0x77fef3c72e90>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\ndef train(model, optimizer, criterion, train_loader, device):\n    model.train()\n    train_loss = 0.0\n    total_correct = 0\n    total_samples = 0\n    for i, batch in enumerate(train_loader):\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(input_ids,attention_mask=attention_mask,labels=labels)\n        loss = outputs.loss\n        train_loss += loss.item()\n        preds = outputs.logits\n        preds = torch.argmax(preds, dim=1)\n        total_correct += (preds == labels).sum().item()\n        total_samples += len(labels)\n\n        if (i+1) % 250 == 0:\n            print('Loss at ',i, \"th batch is: \",loss.item())\n            \n        loss.backward()\n        optimizer.step()\n    \n    train_acc = total_correct / total_samples\n    train_loss = train_loss/len(train_loader)    \n    return train_loss,train_acc\n\n\ndef validate(model, criterion, val_loader, device):\n    model.eval()\n    val_loss = 0.0\n    total_correct = 0\n    total_samples = 0\n    with torch.no_grad():\n        for i, batch in enumerate(val_loader):\n            input_ids, attention_mask, labels = batch\n            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n            outputs = model(input_ids, attention_mask = attention_mask,labels=labels)\n            loss = outputs.loss\n            val_loss += loss.item()\n            preds = outputs.logits\n            preds = torch.argmax(preds, dim=1)\n            total_correct += (preds == labels).sum().item()\n            total_samples += len(labels)\n            \n            if(i%10 == 0):\n                print(\"Preds: \",preds)\n                print(\"Truth: \",labels)\n            \n    val_acc = total_correct / total_samples\n    val_loss /= len(val_loader)\n    print(\"VAL accuracy at epoch: \", val_acc)\n    return val_loss, val_acc","metadata":{"execution":{"iopub.status.busy":"2023-08-11T18:00:00.809809Z","iopub.execute_input":"2023-08-11T18:00:00.810509Z","iopub.status.idle":"2023-08-11T18:00:00.823751Z","shell.execute_reply.started":"2023-08-11T18:00:00.810472Z","shell.execute_reply":"2023-08-11T18:00:00.822806Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support\n\ndef test_(model, criterion, test_loader, device):\n    model.eval()\n    test_loss = 0.0\n    total_correct = 0\n    total_samples = 0\n    true_labels = []\n    predicted_labels = []\n    \n    with torch.no_grad():\n        for i, batch in enumerate(test_loader):\n            input_ids, attention_mask, labels = batch\n            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            test_loss += loss.item()\n            \n            preds = outputs.logits\n            preds = torch.argmax(preds, dim=1)\n            \n            true_labels.extend(labels.tolist())\n            predicted_labels.extend(preds.tolist())\n            \n            total_correct += (preds == labels).sum().item()\n            total_samples += len(labels)\n            \n            if(i%10 == 0):\n                print(\"Preds: \",preds)\n                print(\"Truth: \",labels)\n            \n    test_acc = total_correct / total_samples\n    test_loss /= len(test_loader)\n    \n    # Calculate accuracy, precision, recall and F1 score\n    accuracy = accuracy_score(true_labels, predicted_labels)\n    \n    print(\"TEST Accuracy: {:.4f}\".format(accuracy))\n   \n    \n    \n    \n    return test_loss, test_acc","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:53:33.502536Z","iopub.execute_input":"2023-08-11T17:53:33.502988Z","iopub.status.idle":"2023-08-11T17:53:33.514884Z","shell.execute_reply.started":"2023-08-11T17:53:33.502954Z","shell.execute_reply":"2023-08-11T17:53:33.514061Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"num_epochs = 3\ncriterion = nn.CrossEntropyLoss()\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\nopt = optim.Adam(model.parameters(), lr=5e-7, eps=1e-8)\nmodel.to(device)\nTRAIN_LOSS = []\nVAL_LOSS = []\nTRAIN_ACC = []\nVAL_ACC = []","metadata":{"execution":{"iopub.status.busy":"2023-08-11T17:53:33.516230Z","iopub.execute_input":"2023-08-11T17:53:33.516736Z","iopub.status.idle":"2023-08-11T17:53:39.904531Z","shell.execute_reply.started":"2023-08-11T17:53:33.516701Z","shell.execute_reply":"2023-08-11T17:53:39.903500Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(num_epochs):\n    train_loss,train_acc = train(model,opt,criterion,train_loader,device)\n    val_loss,val_acc = validate(model,criterion,val_loader,device)\n    TRAIN_LOSS.append(train_loss)\n    VAL_LOSS.append(val_loss)\n    TRAIN_ACC.append(train_acc)\n    VAL_ACC.append(val_acc)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T18:00:03.821304Z","iopub.execute_input":"2023-08-11T18:00:03.821666Z","iopub.status.idle":"2023-08-11T18:00:03.937129Z","shell.execute_reply.started":"2023-08-11T18:00:03.821636Z","shell.execute_reply":"2023-08-11T18:00:03.935877Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(num_epochs):                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2 \u001b[2m│   \u001b[0mtrain_loss,train_acc = train(model,opt,criterion,train_loader,device)                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m\u001b[2m│   \u001b[0mval_loss,val_acc = validate(model,criterion,val_loader,device)                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m│   \u001b[0mTRAIN_LOSS.append(train_loss)                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[2m│   \u001b[0mVAL_LOSS.append(val_loss)                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mtrain\u001b[0m:\u001b[94m11\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0mtotal_samples = \u001b[94m0\u001b[0m                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m i, batch \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(train_loader):                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   \u001b[0minput_ids, attention_mask, labels = batch                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m11 \u001b[2m│   │   \u001b[0minput_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(devi    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   │   \u001b[0moptimizer.zero_grad()                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   │   \u001b[0moutputs = model(input_ids,attention_mask=attention_mask,labels=labels)              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   │   \u001b[0mloss = outputs.loss                                                                 \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mRuntimeError: \u001b[0mCUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be \nincorrect.\nFor debugging consider passing \u001b[33mCUDA_LAUNCH_BLOCKING\u001b[0m=\u001b[1;36m1\u001b[0m.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(num_epochs):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>train_loss,train_acc = train(model,opt,criterion,train_loader,device)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>val_loss,val_acc = validate(model,criterion,val_loader,device)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>TRAIN_LOSS.append(train_loss)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>VAL_LOSS.append(val_loss)                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>total_samples = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i, batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(train_loader):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>input_ids, attention_mask, labels = batch                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>11 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(devi    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>optimizer.zero_grad()                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = model(input_ids,attention_mask=attention_mask,labels=labels)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss = outputs.loss                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be \nincorrect.\nFor debugging consider passing <span style=\"color: #808000; text-decoration-color: #808000\">CUDA_LAUNCH_BLOCKING</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}